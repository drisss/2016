{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'driss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_name(name):\n",
    "    last_name = remove_accents(name)\n",
    "    # last_name = re.sub(u'[éèêë]', \"e\",name.lower(), flags=re.I)\n",
    "    # last_name = re.sub(u'[àâä]',\"a\",last_name, flags=re.I)\n",
    "    # last_name = re.sub(u'[ùûü]',\"u\",last_name, flags=re.I)\n",
    "    # last_name = re.sub(u'[ìîï]',\"i\",last_name, flags=re.I)\n",
    "    # last_name = re.sub(u'[òôö]',\"o\",last_name, flags=re.I)\n",
    "    return last_name.tolower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_players_in_tweet(tweet, players):\n",
    "    tweet_players = []\n",
    "\n",
    "    list_token = tknzr.tokenize(tweet)\n",
    "\n",
    "    for token in list_token:\n",
    "        # line = line[:-1]\n",
    "        last_name = remove_accents(token)\n",
    "        last_name = last_name.tolower()\n",
    "\n",
    "        last_name = re.sub(r'([^aeuiyo])([aeuiyo])[aeuiyo]+([^aeuiyo]*)$',\n",
    "                           r'\\g<1><2><3>', last_name, flags=re.I)\n",
    "\n",
    "        for player in players:\n",
    "            if last_name in player.getLastName():\n",
    "                tweet_players .append(player)\n",
    "\n",
    "    return tweet_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_teams_in_tweet(tweet, teams):\n",
    "    tweet_teams = []\n",
    "\n",
    "    list_token = tknzr.tokenize(tweet)\n",
    "\n",
    "    for token in list_token:\n",
    "        # line = line[:-1]\n",
    "        name = remove_accents(token)\n",
    "        name = name.tolower()\n",
    "        name = re.sub(r'([^aeuiyo])([aeuiyo])[aeuiyo]+([^aeuiyo]*)$',\n",
    "                      r'\\g<1><2><3>', name, flags=re.I)\n",
    "\n",
    "        for team in teams:\n",
    "            if name in team.getName():\n",
    "                tweet_teams.append(team)\n",
    "\n",
    "    return tweet_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-af465a8e13a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcount_per\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "f_tweets = codecs.open(sys.argv[2], \"r\", \"utf-8\")\n",
    "f_out = codecs.open(sys.argv[3], \"w\", \"utf-8\")\n",
    "count_per = 0\n",
    "sentence = \"\"\n",
    "\n",
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
